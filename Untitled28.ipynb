{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WyHDNWe7ka-"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "DQJdmvdl7o8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d nguyentrongdai/vietnamese-currency\n",
        "!unzip vietnamese-currency.zip -d vietnamese-currency_data"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6Jt0C5aO7pgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "data_dir = 'vietnamese-currency_data/dataset'\n",
        "train_datagen = ImageDataGenerator(rescale = 1 / 255.0,\n",
        "                                   validation_split = 0.2,\n",
        "                                   rotation_range = 20,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size = (128, 128),\n",
        "    batch_size =32,\n",
        "    class_mode = 'categorical',\n",
        "    subset = 'training')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size = (128, 128),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'categorical',\n",
        "    subset = 'validation')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "HIjs_2DD_Eul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.models import Sequential\n",
        "model=Sequential()\n",
        "model.add(Conv2D(32, (3,3),activation='relu',input_shape=(128,128,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(64, (3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(128, (3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(12,activation='softmax'))\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-fzdgHHR_T-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_generator,epochs=5,validation_data=validation_generator)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0GwvoWUT_YiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('final_model.h5')"
      ],
      "metadata": {
        "id": "kLUnzN2GB6Se",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "uploaded = files.upload()\n",
        "img_path = list(uploaded.keys())[0]\n",
        "img = cv2.imread(img_path)                   # ƒë·ªçc ·∫£nh m√†u\n",
        "img_resized = cv2.resize(img, (128,128))     # resize\n",
        "img_array = img_resized / 255.0              # chu·∫©n h√≥a (0-1)\n",
        "img_array = np.expand_dims(img_array, axis=0) # th√™m chi·ªÅu batch\n",
        "pred = model.predict(img_array)\n",
        "class_index = np.argmax(pred)   # l·∫•y nh√£n c√≥ x√°c su·∫•t cao nh·∫•t\n",
        "confidence = np.max(pred)\n",
        "labels = list(train_generator.class_indices.keys())\n",
        "print(\"D·ª± ƒëo√°n:\", labels[class_index], \"- ƒê·ªô tin c·∫≠y:\", confidence)\n",
        "\n",
        "# Hi·ªÉn th·ªã ·∫£nh\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.title(f\"D·ª± ƒëo√°n: {labels[class_index]}\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ikFFE4cBBLwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Dictionary th√¥ng tin ti·ªÅn\n",
        "money_info = {\n",
        "    \"000000\": \"X\",\n",
        "    \"000200\": \"200 ƒë·ªìng\",\n",
        "    \"000500\": \"500 ƒë·ªìng\",\n",
        "    \"001000\": \"1 000 ƒë·ªìng\",\n",
        "    \"002000\": \"2 000 ƒë·ªìng\",\n",
        "    \"005000\": \"5 000 ƒë·ªìng\",\n",
        "    \"010000\": \"10 000 ƒë·ªìng\",\n",
        "    \"020000\": \"20 000 ƒë·ªìng\",\n",
        "    \"050000\": \"50 000 ƒë·ªìng\",\n",
        "    \"100000\": \"100 000 ƒë·ªìng\",\n",
        "    \"200000\": \"200 000 ƒë·ªìng\",\n",
        "    \"500000\": \"500 000 ƒë·ªìng\"\n",
        "}\n",
        "\n",
        "# Load model CNN ƒë√£ train\n",
        "model_path = 'final_model.h5'  # ƒë·ªïi theo ƒë∆∞·ªùng d·∫´n model c·ªßa b·∫°n\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Nh√£n l·ªõp (key t∆∞∆°ng ·ª©ng v·ªõi m·ªánh gi√°)\n",
        "labels = [\"000200\", \"000500\", \"001000\", \"002000\", \"005000\", \"010000\", \"020000\", \"050000\", \"100000\", \"200000\", \"500000\", \"000000\"]\n",
        "\n",
        "# H√†m d·ª± ƒëo√°n\n",
        "def predict_currency(img):\n",
        "    img = img.convert(\"RGB\").resize((128,128))\n",
        "    x = np.array(img)/255.0\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    preds = model.predict(x)\n",
        "    class_idx = np.argmax(preds)\n",
        "    confidence = preds[0][class_idx]\n",
        "    return money_info.get(labels[class_idx], labels[class_idx]), round(confidence*100, 2)\n",
        "\n",
        "# H√†m reset ·∫£nh\n",
        "def reset_image():\n",
        "    return None, \"\", \"\"\n",
        "\n",
        "# CSS n√¢ng cao: font, m√†u n·ªÅn, icon, bo g√≥c\n",
        "css_style = \"\"\"\n",
        "body {\n",
        "    background: linear-gradient(to right, #c7f0c7, #fff7d6);\n",
        "    font-family: 'Poppins', sans-serif;\n",
        "}\n",
        "h1 {\n",
        "    color: #056608;\n",
        "    font-family: 'Orbitron', sans-serif;\n",
        "    font-size: 36px;\n",
        "}\n",
        "#predict-btn, #reset-btn {\n",
        "    background-color: #ffd700;\n",
        "    color: #000;\n",
        "    font-weight: bold;\n",
        "    font-size: 18px;\n",
        "}\n",
        ".gr-button {border-radius: 15px; padding: 10px 20px;}\n",
        ".gr-box {\n",
        "    border: 2px solid #056608;\n",
        "    border-radius: 15px;\n",
        "    padding: 15px;\n",
        "    background-color: rgba(240, 255, 240, 0.9);\n",
        "}\n",
        "#label_output .gr-label::before {content: 'üí∞ ';}\n",
        "#confidence_output .gr-label::before {content: '‚úÖ ';}\n",
        "\"\"\"\n",
        "\n",
        "# Giao di·ªán Gradio n√¢ng c·∫•p\n",
        "with gr.Blocks(css=css_style) as demo:\n",
        "    gr.Markdown(\"<h1 style='text-align:center;'>·ª®ng d·ª•ng nh·∫≠n di·ªán ti·ªÅn Vi·ªát Nam üíµüí∞</h1>\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            img_input = gr.Image(type=\"pil\", label=\"Ch·ªçn ·∫£nh ho·∫∑c k√©o th·∫£ v√†o ƒë√¢y\")\n",
        "            btn_predict = gr.Button(\"Nh·∫≠n di·ªán ü™ô\", elem_id=\"predict-btn\")\n",
        "            btn_reset = gr.Button(\"Ch·ªçn ·∫£nh kh√°c üîÑ\", elem_id=\"reset-btn\")\n",
        "        with gr.Column():\n",
        "            label_output = gr.Textbox(label=\"Lo·∫°i ti·ªÅn d·ª± ƒëo√°n\", interactive=False)\n",
        "            confidence_output = gr.Textbox(label=\"ƒê·ªô ch√≠nh x√°c (%)\", interactive=False)\n",
        "\n",
        "    # N√∫t d·ª± ƒëo√°n\n",
        "    btn_predict.click(predict_currency, inputs=img_input, outputs=[label_output, confidence_output])\n",
        "    # N√∫t reset ·∫£nh v√† x√≥a k·∫øt qu·∫£\n",
        "    btn_reset.click(reset_image, inputs=None, outputs=[img_input, label_output, confidence_output])\n",
        "\n",
        "# Ch·∫°y app tr·ª±c ti·∫øp tr√™n Colab\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7OCdYhQ-kZuU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}